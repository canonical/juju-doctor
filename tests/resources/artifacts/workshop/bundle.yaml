bundle: kubernetes
applications:
  alertmanager-k8s:
    charm: alertmanager-k8s
    channel: latest/stable
    revision: 157
    resources:
      alertmanager-image: 99
    scale: 1
    options:
      config_file: "global:\n  # The smarthost and SMTP sender used for mail notifications.\n
        \ smtp_smarthost: 'localhost:25'\n  smtp_from: 'alertmanager@example.org'\n\n#
        The root route on which each incoming alert enters.\nroute:\n  # The root
        route must not have any matchers as it is the entry point for\n  # all alerts.
        It needs to have a receiver configured so alerts that do not\n  # match any
        of the sub-routes are sent to someone.\n  receiver: 'team-X-mails'\n\n  #
        The labels by which incoming alerts are grouped together. For example,\n  #
        multiple alerts coming in for cluster=A and alertname=LatencyHigh would\n
        \ # be batched into a single group.\n  #\n  # To aggregate by all possible
        labels use '...' as the sole label name.\n  # This effectively disables aggregation
        entirely, passing through all\n  # alerts as-is. This is unlikely to be what
        you want, unless you have\n  # a very low alert volume or your upstream notification
        system performs\n  # its own grouping. Example: group_by: [...]\n  group_by:
        ['alertname', 'cluster']\n\n  # When a new group of alerts is created by an
        incoming alert, wait at\n  # least 'group_wait' to send the initial notification.\n
        \ # This way ensures that you get multiple alerts for the same group that
        start\n  # firing shortly after another are batched together on the first\n
        \ # notification.\n  group_wait: 30s\n\n  # When the first notification was
        sent, wait 'group_interval' to send a batch\n  # of new alerts that started
        firing for that group.\n  group_interval: 5m\n\n  # If an alert has successfully
        been sent, wait 'repeat_interval' to\n  # resend them.\n  repeat_interval:
        3h\n\n  # All the above attributes are inherited by all child routes and can\n
        \ # overwritten on each.\n\n  # The child route trees.\n  routes:\n  # This
        route performs a regular expression match on alert labels to\n  # catch alerts
        that are related to a list of services.\n  - matchers:\n    - service=~\"^(foo1|foo2|baz)$\"\n
        \   receiver: team-X-mails\n\n    # The service has a sub-route for critical
        alerts, any alerts\n    # that do not match, i.e. severity != critical, fall-back
        to the\n    # parent node and are sent to 'team-X-mails'\n    routes:\n    -
        matchers:\n      - severity=\"critical\"\n      receiver: team-X-pager\n\n
        \ - matchers:\n    - service=\"files\"\n    receiver: team-Y-mails\n\n    routes:\n
        \   - matchers:\n      - severity=\"critical\"\n      receiver: team-Y-pager\n\n
        \ # This route handles all alerts coming from a database service. If there's\n
        \ # no team to handle it, it defaults to the DB team.\n  - matchers:\n    -
        service=\"database\"\n\n    receiver: team-DB-pager\n    # Also group alerts
        by affected database.\n    group_by: [alertname, cluster, database]\n\n    routes:\n
        \   - matchers:\n      - owner=\"team-X\"\n      receiver: team-X-pager\n\n
        \   - matchers:\n      - owner=\"team-Y\"\n      receiver: team-Y-pager\n\n\n#
        Inhibition rules allow to mute a set of alerts given that another alert is\n#
        firing.\n# We use this to mute any warning-level notifications if the same
        alert is\n# already critical.\ninhibit_rules:\n- source_matchers:\n    - severity=\"critical\"\n
        \ target_matchers:\n    - severity=\"warning\"\n  # Apply inhibition if the
        alertname is the same.\n  # CAUTION: \n  #   If all label names listed in
        `equal` are missing \n  #   from both the source and target alerts,\n  #   the
        inhibition rule will apply!\n  equal: ['alertname']\n\n\nreceivers:\n- name:
        'team-X-mails'\n  email_configs:\n  - to: 'team-X+alerts@example.org, team-Y+alerts@example.org'\n\n-
        name: 'team-X-pager'\n  email_configs:\n  - to: 'team-X+alerts-critical@example.org'\n
        \ pagerduty_configs:\n  - routing_key: <team-X-key>\n\n- name: 'team-Y-mails'\n
        \ email_configs:\n  - to: 'team-Y+alerts@example.org'\n\n- name: 'team-Y-pager'\n
        \ pagerduty_configs:\n  - routing_key: <team-Y-key>\n\n- name: 'team-DB-pager'\n
        \ pagerduty_configs:\n  - routing_key: <team-DB-key>"
    constraints: arch=amd64
    storage:
      data: kubernetes,1,1024M
    trust: true
  prometheus-k8s:
    charm: prometheus-k8s
    channel: latest/stable
    revision: 234
    resources:
      prometheus-image: 151
    scale: 1
    constraints: arch=amd64
    storage:
      database: kubernetes,1,1024M
    trust: true
relations:
- - alertmanager-k8s:alerting
  - prometheus-k8s:alertmanager
